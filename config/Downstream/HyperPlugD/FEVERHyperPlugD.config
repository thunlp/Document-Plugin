[train] #train parameters
epoch = 6
batch_size = 64

shuffle = True

reader_num = 8

optimizer = AdamW
learning_rate = 2e-5
weight_decay = 1e-5


warmup_steps=2000
training_steps=50000
max_grad_norm=0.0

scheduler=t5

inspector_para=*

max_len = 128
ctx_len = 512

layerth=12
bottleneck_dim=16


[eval] #eval parameters
batch_size = 64
reader_num = 8

[data] #data parameters
train_dataset_type = FEVER
train_formatter_type = FEVERPlugD
train_data_path = data/dpr-top5/fever-train-kilt.jsonl

valid_dataset_type = FEVER
valid_formatter_type = FEVERPlugD
valid_data_path = data/dpr-top5/fever-dev-kilt.jsonl

labelids = [4273,150]

[model] #model parameters
model_name = TextClassification
pretrained_model = t5-large

model_type = HyperPlugD

[output] #output parameters
output_time = 20
test_time = 1
output_grad_step = 400

model_name = FEVERHyperPlugD
output_function = binary
