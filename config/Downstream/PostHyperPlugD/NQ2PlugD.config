[train] #train parameters
epoch = 10
batch_size = 32

shuffle = True

reader_num = 4

optimizer = AdamW
learning_rate = 1e-3
weight_decay = 1e-5


warmup_steps=2000
training_steps=50000
max_grad_norm=2.0

scheduler=t5

inspector_para=*plug*

max_len = 64
ctx_len = 512
ans_max_len = 64

layerth = 12
mid_dim=2
bottleneck_dim=16

doc_pos=True

[eval] #eval parameters
batch_size = 32
reader_num = 4

[data] #data parameters
train_dataset_type = OpenQA2
train_formatter_type = OpenQAPlugD
train_data_path = ../data/NQ/train.jsonl

valid_dataset_type = OpenQA2
valid_formatter_type = OpenQAPlugD
valid_data_path = ../data/NQ/dev.jsonl

test_dataset_type = OpenQA2
test_formatter_type = OpenQAPlugD
test_data_path = ../data/NQ/dev.jsonl


[model] #model parameters
model_name = OpenQAAdapter
pretrained_model = t5-large

model_type = PostPlugD

[output] #output parameters
output_time = 20
test_time = 1
output_grad_step = 200

model_name = NQPlugD
output_function = squad
