[train] #train parameters
epoch = 16
batch_size = 32

shuffle = True

reader_num = 4

optimizer = AdamW
learning_rate = 2e-5
weight_decay = 1e-5

ctx_len = 512
ans_len = 128
que_len = 196

mlm_ratio=0.5
mlm_mean_len=3

warmup_steps=2000
training_steps=50000
max_grad_norm=1.5


valid_mode=step
step_epoch=1000

scheduler=t5

layerth=12

no_valid = True


[eval] #eval parameters
batch_size = 16

[data] #data parameters
train_dataset_type = kara
train_formatter_type = PlugDPL
train_data_path = data/c4-kara
train_kara_namespace = C4
train_kara_dataset = train
train_kara_version = 1st

valid_dataset_type = kara
valid_formatter_type = PlugDPL
valid_data_path = data/c4-kara
valid_kara_namespace = C4
valid_kara_dataset = train
valid_kara_version = 1st


[model] #model parameters
model_name = PlugD
pretrained_model = t5-large

model_type = PlugD

[output] #output parameters
output_time = 20
test_time = 1

model_name = PlugD-large
output_function = mlm

